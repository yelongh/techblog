---
layout: post
title: Spanner In Details
date: '2022-02-01 10:11'
excerpt: This blog post will discuss all the details in Spanner.
comments: true
---


- Albeit there exist many How-To's, most of the newer once are covering finetuning VGG or Inception Models and not AlexNet. Although the idea behind finetuning is the same, the major difference is, that Tensorflow (as well as Keras) already ship with VGG or Inception classes and include the weights (pretrained on ImageNet). For the AlexNet model, we have to do a bit more on our own.
- Another reason is that for a lot of my personal projects AlexNet works quite well and there is no reason to switch to any of the more heavy-weight models to gain probably another .5% accuracy boost. As the models get deeper they naturally need more computational time, which in some projects I can't afford.
- In the past, I used mainly [Caffe](http://caffe.berkeleyvision.org/) to finetune convolutional networks. But to be honest, I found it quite cumbersome (e.g. model definition via .prototxt, the model structure with blobs...) to work with Caffe. After some time with Keras, I recently switched to pure TensorFlow and now I want to be able to finetune the same network as previously, but using just TensorFlow.
- Well and I think the main reason for this article is that working on a project like this, helps me to better understand TensorFlow in general.

## Disclaimer

After finishing to write this article I ended up having written another very long post. Basically it is divided into two parts: In the first part I created a class to define the model graph of AlexNet together with a function to load the pretrained weights and in the second part how to actually use this class to finetune AlexNet on a new dataset. Although I recommend reading the first part, click [here](#finetune) to skip the first part and go directly on how to finetune AlexNet.

And next: This is not an introduction neither to TensorFlow nor to finetuning or convolutional networks in general. I'll explain most of the steps you need to do, but basic knowledge of TensorFlow and machine/deep learning is required to fully understand everything.

## Getting the pretrained weights
Unlike VGG or Inception, TensorFlow doesn't ship with a pretrained AlexNet. Caffe does, but it's not to trivial to convert the weights manually in a structure usable by TensorFlow. Luckily [Caffe to TensorFlow](https://github.com/ethereon/caffe-tensorflow) exists, a small conversion tool, to translate any `*prototxt` model definition from caffe to python code and a TensorFlow model, as well as conversion of the weights. I tried it on my own and it works pretty straight forward. Anyway, [here](http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/) you can download the already converted weights.


